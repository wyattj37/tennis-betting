{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_rKFEluaNHj"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPpj0NOuaOWa",
    "outputId": "3c931f4b-6d72-4913-a03a-111bf4b840cf"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klhNIOBM7f17"
   },
   "outputs": [],
   "source": [
    "path_to_match_data = '/content/drive/My Drive/tennis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5z2b4tjaa3u",
    "outputId": "e156709c-5a85-4a3b-81c2-bad221770ff0"
   },
   "outputs": [],
   "source": [
    "# Load in csv files\n",
    "non_training_year = 2010 # decide year before which matches won't be trained or tested\n",
    "atp_csv_files_all = []\n",
    "atp_csv_files_before = []\n",
    "atp_csv_files_after = []\n",
    "for i in range(1995, 2024):\n",
    "  df = pd.read_csv(f'{path_to_match_data}/atp_matches_{i}.csv')\n",
    "  atp_csv_files_all.append(df)\n",
    "  if i < non_training_year:\n",
    "    atp_csv_files_before.append(df)\n",
    "  else:\n",
    "    atp_csv_files_after.append(df)\n",
    "  print(f\"Year {i} loaded\")\n",
    "\n",
    "atp_matches_all = pd.concat(atp_csv_files_all, ignore_index=True)\n",
    "atp_matches_before_df = pd.concat(atp_csv_files_before, ignore_index=True)\n",
    "atp_matches_after_df = pd.concat(atp_csv_files_after, ignore_index=True)\n",
    "atp_players_df = pd.read_csv('/content/drive/My Drive/tennis/atp_players.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R09aoRJS2pcb",
    "outputId": "4f6d0845-285e-4593-c99f-569ef98f2335"
   },
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    # Remove rows where the score is \"W/O\"\n",
    "    df = df[df['score'] != 'W/O']\n",
    "\n",
    "    # Replace values in winner_hand and loser_hand columns\n",
    "    df['winner_hand'] = df['winner_hand'].apply(lambda x: 'R' if x not in ['L', 'R'] else x)\n",
    "    df['loser_hand'] = df['loser_hand'].apply(lambda x: 'R' if x not in ['L', 'R'] else x)\n",
    "    df['tourney_date'] = pd.to_datetime(df['tourney_date'], format='%Y%m%d')\n",
    "\n",
    "    # Replace NaN values in specific columns with 0\n",
    "    cols_with_zeros = ['w_1stWon', 'w_1stIn', 'w_2ndWon', 'w_svpt', 'w_bpSaved', 'w_bpFaced',\n",
    "                       'l_1stWon', 'l_1stIn', 'l_2ndWon', 'l_svpt', 'l_bpSaved', 'l_bpFaced']\n",
    "\n",
    "    for col in cols_with_zeros:\n",
    "        df[col].fillna(0, inplace=True)\n",
    "\n",
    "    # Replace NaN values in \"w_height\" and \"l_height\" with the column average\n",
    "    for col in ['winner_ht', 'loser_ht']:\n",
    "        mean_value = df[col].mean()\n",
    "        df[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "    # just call NA surface Hard\n",
    "    df['surface'].fillna(\"Hard\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean all DataFrames\n",
    "atp_matches_all = clean_dataframe(atp_matches_all)\n",
    "atp_matches_before_df = clean_dataframe(atp_matches_before_df)\n",
    "atp_matches_after_df = clean_dataframe(atp_matches_after_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bpMxjydgWWl"
   },
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "atp_matches_before_df = atp_matches_before_df.drop(['draw_size', 'winner_seed', 'loser_seed', 'winner_entry', 'loser_entry', 'winner_rank', 'winner_rank_points', 'loser_rank', 'loser_rank_points'], axis=1)\n",
    "atp_matches_after_df = atp_matches_after_df.drop(['draw_size', 'winner_seed', 'loser_seed', 'winner_entry', 'loser_entry', 'winner_rank', 'winner_rank_points', 'loser_rank', 'loser_rank_points'], axis=1)\n",
    "atp_matches_all = atp_matches_all.drop(['draw_size', 'winner_seed', 'loser_seed', 'winner_entry', 'loser_entry', 'winner_rank', 'winner_rank_points', 'loser_rank', 'loser_rank_points'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNG4WkDQblME"
   },
   "outputs": [],
   "source": [
    "# Make first player feature, id\n",
    "atp_player_features = pd.DataFrame({\n",
    "    'player_id' : pd.concat([\n",
    "    pd.Series(atp_matches_all['winner_id'].unique()),\n",
    "    pd.Series(atp_matches_all['loser_id'].unique())]).unique()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lf2ESpTeiN90"
   },
   "outputs": [],
   "source": [
    "# make total_wins feature\n",
    "wins_count_before = atp_matches_before_df['winner_id'].value_counts().reset_index()\n",
    "wins_count_before.columns = ['player_id', 'total_wins']\n",
    "atp_player_features = atp_player_features.merge(wins_count_before, on='player_id', how='left')\n",
    "atp_player_features['total_wins'].fillna(0, inplace=True)\n",
    "\n",
    "# make total_losses feature\n",
    "loss_count_before = atp_matches_before_df['loser_id'].value_counts().reset_index()\n",
    "loss_count_before.columns = ['player_id', 'total_losses']\n",
    "atp_player_features = atp_player_features.merge(loss_count_before, on='player_id', how='left')\n",
    "atp_player_features['total_losses'].fillna(0, inplace=True)\n",
    "\n",
    "# make total_wins/losses_(surface) features\n",
    "for surface in ['Hard', 'Carpet', 'Clay', 'Grass']:\n",
    "  matches_on_surface = atp_matches_before_df[atp_matches_before_df['surface'] == surface]\n",
    "  wins_count_surface = matches_on_surface['winner_id'].value_counts().reset_index()\n",
    "  wins_count_surface.columns = ['player_id', f'total_wins_on_{surface}']\n",
    "  atp_player_features = atp_player_features.merge(wins_count_surface, on='player_id', how='left')\n",
    "  atp_player_features[f'total_wins_on_{surface}'].fillna(0, inplace=True)\n",
    "  loss_count_surface = matches_on_surface['loser_id'].value_counts().reset_index()\n",
    "  loss_count_surface.columns = ['player_id', f'total_losses_on_{surface}']\n",
    "  atp_player_features = atp_player_features.merge(loss_count_surface, on='player_id', how='left')\n",
    "  atp_player_features[f'total_losses_on_{surface}'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bGZw9QXlser"
   },
   "outputs": [],
   "source": [
    "# Calculate wins/losses in best of 3/5 sets\n",
    "for best_of in [3, 5]:\n",
    "    matches_best_of = atp_matches_before_df[atp_matches_before_df['best_of'] == best_of]\n",
    "    wins_count_best_of = matches_best_of['winner_id'].value_counts().reset_index()\n",
    "    wins_count_best_of.columns = ['player_id', f'total_wins_best_of_{best_of}']\n",
    "    atp_player_features = atp_player_features.merge(wins_count_best_of, on='player_id', how='left')\n",
    "    atp_player_features[f'total_wins_best_of_{best_of}'].fillna(0, inplace=True)\n",
    "\n",
    "    loss_count_best_of = matches_best_of['loser_id'].value_counts().reset_index()\n",
    "    loss_count_best_of.columns = ['player_id', f'total_losses_best_of_{best_of}']\n",
    "    atp_player_features = atp_player_features.merge(loss_count_best_of, on='player_id', how='left')\n",
    "    atp_player_features[f'total_losses_best_of_{best_of}'].fillna(0, inplace=True)\n",
    "\n",
    "for hand in ['L', 'R']:\n",
    "    wins_count_hand = atp_matches_before_df[atp_matches_before_df['winner_hand'] == hand]['winner_id'].value_counts().reset_index()\n",
    "    wins_count_hand.columns = ['player_id', f'total_wins_vs_{hand}']\n",
    "    atp_player_features = atp_player_features.merge(wins_count_hand, on='player_id', how='left')\n",
    "    atp_player_features[f'total_wins_vs_{hand}'].fillna(0, inplace=True)\n",
    "\n",
    "    losses_count_hand = atp_matches_before_df[atp_matches_before_df['loser_hand'] == hand]['loser_id'].value_counts().reset_index()\n",
    "    losses_count_hand.columns = ['player_id', f'total_losses_vs_{hand}']\n",
    "    atp_player_features = atp_player_features.merge(losses_count_hand, on='player_id', how='left')\n",
    "    atp_player_features[f'total_losses_vs_{hand}'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxk-M42tqDqa"
   },
   "outputs": [],
   "source": [
    "# make brk_pts_srvd, brk_pts_lost, brk_pts_faced, brk_pts_saved\n",
    "# make first_serves, first_serve_wins, second_serves, second_serve_wins, first_returns, first_return_wins, second_returns, second_return_wins\n",
    "serve_return_stats = atp_matches_before_df.groupby('winner_id').agg({\n",
    "    'w_svpt': 'sum',\n",
    "    'w_1stIn' : 'sum',\n",
    "    'w_1stWon': 'sum',\n",
    "    'w_2ndWon': 'sum',\n",
    "    'l_svpt': 'sum',\n",
    "    'l_1stIn' : 'sum',\n",
    "    'l_1stWon': 'sum',\n",
    "    'l_2ndWon': 'sum',\n",
    "    'w_bpSaved': 'sum',\n",
    "    'w_bpFaced': 'sum',\n",
    "    'l_bpSaved' : 'sum',\n",
    "    'l_bpFaced' : 'sum'\n",
    "}).reset_index()\n",
    "serve_return_stats.columns = ['player_id', 'total_w_svpt', 'total_w_1stIn', 'total_w_1stWon', 'total_w_2ndWon', 'total_w_retpt', 'total_w_1stRet','total_w_1stRetLost', 'total_w_2ndRetLost', 'total_w_bpAgainst_Won', 'total_w_bpAgainst', 'total_w_bpFor_Lost', 'total_w_bpFor']\n",
    "\n",
    "serve_return_stats_loser = atp_matches_before_df.groupby('loser_id').agg({\n",
    "    'l_svpt': 'sum',\n",
    "    'l_1stIn' : 'sum',\n",
    "    'l_1stWon': 'sum',\n",
    "    'l_2ndWon': 'sum',\n",
    "    'w_svpt': 'sum',\n",
    "    'w_1stIn' : 'sum',\n",
    "    'w_1stWon': 'sum',\n",
    "    'w_2ndWon': 'sum',\n",
    "    'l_bpSaved': 'sum',\n",
    "    'l_bpFaced': 'sum',\n",
    "    'w_bpSaved' : 'sum',\n",
    "    'w_bpFaced' : 'sum'\n",
    "}).reset_index()\n",
    "serve_return_stats_loser.columns = ['player_id', 'total_l_svpt', 'total_l_1stIn', 'total_l_1stWon', 'total_l_2ndWon', 'total_l_retpt', 'total_l_1stRet','total_l_1stRetLost', 'total_l_2ndRetLost', 'total_l_bpAgainst_Won', 'total_l_bpAgainst', 'total_l_bpFor_Lost', 'total_l_bpFor']\n",
    "\n",
    "# Merge winners and losers stats into one DataFrame\n",
    "serve_return_stats_all = pd.merge(serve_return_stats, serve_return_stats_loser, on='player_id', how='outer')\n",
    "serve_return_stats_all.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate serve, return, break features\n",
    "serve_return_stats_all['total_serves'] = serve_return_stats_all['total_w_svpt'] + serve_return_stats_all['total_l_svpt']\n",
    "serve_return_stats_all['total_first_serves'] = serve_return_stats_all['total_w_1stIn'] + serve_return_stats_all['total_l_1stIn']\n",
    "serve_return_stats_all['total_second_serves'] = serve_return_stats_all['total_serves'] - serve_return_stats_all['total_first_serves']\n",
    "serve_return_stats_all['first_serves_wins'] = serve_return_stats_all['total_w_1stWon'] + serve_return_stats_all['total_l_1stWon']\n",
    "serve_return_stats_all['second_serves_wins'] = serve_return_stats_all['total_w_2ndWon'] + serve_return_stats_all['total_l_2ndWon']\n",
    "\n",
    "serve_return_stats_all['total_returns'] = serve_return_stats_all['total_w_retpt'] + serve_return_stats_all['total_l_retpt']\n",
    "serve_return_stats_all['total_first_returns'] = serve_return_stats_all['total_w_1stRet'] + serve_return_stats_all['total_l_1stRet']\n",
    "serve_return_stats_all['total_second_returns'] = serve_return_stats_all['total_returns'] - serve_return_stats_all['total_first_returns']\n",
    "serve_return_stats_all['first_return_wins'] = serve_return_stats_all['total_first_returns'] - (serve_return_stats_all['total_w_1stRetLost'] + serve_return_stats_all['total_l_1stRetLost'])\n",
    "serve_return_stats_all['second_return_wins'] = serve_return_stats_all['total_second_returns'] - (serve_return_stats_all['total_w_2ndRetLost'] + serve_return_stats_all['total_l_2ndRetLost'])\n",
    "\n",
    "serve_return_stats_all['break_points_against_won'] = serve_return_stats_all['total_w_bpAgainst_Won'] + serve_return_stats_all['total_l_bpAgainst_Won']\n",
    "serve_return_stats_all['break_points_against'] = serve_return_stats_all['total_w_bpAgainst'] + serve_return_stats_all['total_l_bpAgainst']\n",
    "serve_return_stats_all['break_points_against_lost'] =  serve_return_stats_all['break_points_against'] - serve_return_stats_all['break_points_against_won']\n",
    "serve_return_stats_all['break_points_for_lost'] = serve_return_stats_all['total_w_bpFor_Lost'] + serve_return_stats_all['total_l_bpFor_Lost']\n",
    "serve_return_stats_all['break_points_for'] = serve_return_stats_all['total_w_bpFor'] + serve_return_stats_all['total_l_bpFor']\n",
    "serve_return_stats_all['break_points_for_won'] = serve_return_stats_all['break_points_for'] - serve_return_stats_all['break_points_for_lost']\n",
    "\n",
    "# Merge with atp_player_features\n",
    "atp_player_features = atp_player_features.merge(serve_return_stats_all, on='player_id', how='left')\n",
    "\n",
    "# Take care of players in ATP_all but after 2016\n",
    "columns_to_replace = [\n",
    "    'total_serves', 'total_first_serves', 'total_second_serves',\n",
    "    'first_serves_wins', 'second_serves_wins',\n",
    "    'total_returns', 'total_first_returns', 'total_second_returns',\n",
    "    'first_return_wins', 'second_return_wins',\n",
    "    'break_points_against_won', 'break_points_against', 'break_points_against_lost',\n",
    "    'break_points_for_lost', 'break_points_for', 'break_points_for_won'\n",
    "]\n",
    "atp_player_features[columns_to_replace] = atp_player_features[columns_to_replace].fillna(0)\n",
    "\n",
    "# Drop w/l columns no longer needed\n",
    "columns_to_drop = [\n",
    "    'total_w_svpt', 'total_w_1stIn', 'total_w_1stWon', 'total_w_2ndWon',\n",
    "    'total_w_retpt', 'total_w_1stRet', 'total_w_1stRetLost', 'total_w_2ndRetLost',\n",
    "    'total_w_bpAgainst_Won', 'total_w_bpAgainst', 'total_w_bpFor_Lost',\n",
    "    'total_w_bpFor', 'total_l_svpt', 'total_l_1stIn', 'total_l_1stWon',\n",
    "    'total_l_2ndWon', 'total_l_retpt', 'total_l_1stRet', 'total_l_1stRetLost',\n",
    "    'total_l_2ndRetLost', 'total_l_bpAgainst_Won', 'total_l_bpAgainst',\n",
    "    'total_l_bpFor_Lost', 'total_l_bpFor'\n",
    "]\n",
    "\n",
    "atp_player_features = atp_player_features.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-y4B97H4vmv"
   },
   "outputs": [],
   "source": [
    "# Making the Glicko-2 System\n",
    "\n",
    "WIN = 1.\n",
    "DRAW = 0.5\n",
    "LOSS = 0.\n",
    "\n",
    "\n",
    "MU = 1500\n",
    "PHI = 350\n",
    "SIGMA = 0.06\n",
    "TAU = 1.0\n",
    "EPSILON = 0.000001\n",
    "\n",
    "\n",
    "class Rating(object):\n",
    "    def __init__(self, mu=MU, phi=PHI, sigma=SIGMA):\n",
    "        self.mu = mu\n",
    "        self.phi = phi\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __repr__(self):\n",
    "        c = type(self)\n",
    "        args = (c.__module__, c.__name__, self.mu, self.phi, self.sigma)\n",
    "        return '%s.%s(mu=%.3f, phi=%.3f, sigma=%.3f)' % args\n",
    "\n",
    "\n",
    "class Glicko2(object):\n",
    "    def __init__(self, mu=MU, phi=PHI, sigma=SIGMA, tau=TAU, epsilon=EPSILON):\n",
    "        self.mu = mu\n",
    "        self.phi = phi\n",
    "        self.sigma = sigma\n",
    "        self.tau = tau\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def create_rating(self, mu=None, phi=None, sigma=None):\n",
    "        if mu is None:\n",
    "            mu = self.mu\n",
    "        if phi is None:\n",
    "            phi = self.phi\n",
    "        if sigma is None:\n",
    "            sigma = self.sigma\n",
    "        return Rating(mu, phi, sigma)\n",
    "\n",
    "    def scale_down(self, rating, ratio=173.7178):\n",
    "        mu = (rating.mu - self.mu) / ratio\n",
    "        phi = rating.phi / ratio\n",
    "        return self.create_rating(mu, phi, rating.sigma)\n",
    "\n",
    "    def scale_up(self, rating, ratio=173.7178):\n",
    "        mu = rating.mu * ratio + self.mu\n",
    "        phi = rating.phi * ratio\n",
    "        return self.create_rating(mu, phi, rating.sigma)\n",
    "\n",
    "    def reduce_impact(self, rating):\n",
    "        \"\"\"The original form is `g(RD)`. This function reduces the impact of\n",
    "        games as a function of an opponent's RD.\n",
    "        \"\"\"\n",
    "        return 1. / math.sqrt(1 + (3 * rating.phi ** 2) / (math.pi ** 2))\n",
    "\n",
    "    def expect_score(self, rating, other_rating, impact):\n",
    "        return 1. / (1 + math.exp(-impact * (rating.mu - other_rating.mu)))\n",
    "\n",
    "    def determine_sigma(self, rating, difference, variance):\n",
    "        \"\"\"Determines new sigma.\"\"\"\n",
    "        phi = rating.phi\n",
    "        difference_squared = difference ** 2\n",
    "        # 1. Let a = ln(s^2), and define f(x)\n",
    "        alpha = math.log(rating.sigma ** 2)\n",
    "\n",
    "        def f(x):\n",
    "            \"\"\"This function is twice the conditional log-posterior density of\n",
    "            phi, and is the optimality criterion.\n",
    "            \"\"\"\n",
    "            tmp = phi ** 2 + variance + math.exp(x)\n",
    "            a = math.exp(x) * (difference_squared - tmp) / (2 * tmp ** 2)\n",
    "            b = (x - alpha) / (self.tau ** 2)\n",
    "            return a - b\n",
    "\n",
    "        # 2. Set the initial values of the iterative algorithm.\n",
    "        a = alpha\n",
    "        if difference_squared > phi ** 2 + variance:\n",
    "            b = math.log(difference_squared - phi ** 2 - variance)\n",
    "        else:\n",
    "            k = 1\n",
    "            while f(alpha - k * math.sqrt(self.tau ** 2)) < 0:\n",
    "                k += 1\n",
    "            b = alpha - k * math.sqrt(self.tau ** 2)\n",
    "        # 3. Let fA = f(A) and f(B) = f(B)\n",
    "        f_a, f_b = f(a), f(b)\n",
    "        # 4. While |B-A| > e, carry out the following steps.\n",
    "        # (a) Let C = A + (A - B)fA / (fB-fA), and let fC = f(C).\n",
    "        # (b) If fCfB < 0, then set A <- B and fA <- fB; otherwise, just set\n",
    "        #     fA <- fA/2.\n",
    "        # (c) Set B <- C and fB <- fC.\n",
    "        # (d) Stop if |B-A| <= e. Repeat the above three steps otherwise.\n",
    "        while abs(b - a) > self.epsilon:\n",
    "            c = a + (a - b) * f_a / (f_b - f_a)\n",
    "            f_c = f(c)\n",
    "            if f_c * f_b < 0:\n",
    "                a, f_a = b, f_b\n",
    "            else:\n",
    "                f_a /= 2\n",
    "            b, f_b = c, f_c\n",
    "        # 5. Once |B-A| <= e, set s' <- e^(A/2)\n",
    "        return math.exp(1) ** (a / 2)\n",
    "\n",
    "    def rate(self, rating, series):\n",
    "        # Step 2. For each player, convert the rating and RD's onto the\n",
    "        #         Glicko-2 scale.\n",
    "        rating = self.scale_down(rating)\n",
    "        # Step 3. Compute the quantity v. This is the estimated variance of the\n",
    "        #         team's/player's rating based only on game outcomes.\n",
    "        # Step 4. Compute the quantity difference, the estimated improvement in\n",
    "        #         rating by comparing the pre-period rating to the performance\n",
    "        #         rating based only on game outcomes.\n",
    "        variance_inv = 0\n",
    "        difference = 0\n",
    "        if not series:\n",
    "            # If the team didn't play in the series, do only Step 6\n",
    "            phi_star = math.sqrt(rating.phi ** 2 + rating.sigma ** 2)\n",
    "            return self.scale_up(self.create_rating(rating.mu, phi_star, rating.sigma))\n",
    "        for actual_score, other_rating in series:\n",
    "            other_rating = self.scale_down(other_rating)\n",
    "            impact = self.reduce_impact(other_rating)\n",
    "            expected_score = self.expect_score(rating, other_rating, impact)\n",
    "            variance_inv += impact ** 2 * expected_score * (1 - expected_score)\n",
    "            difference += impact * (actual_score - expected_score)\n",
    "        difference /= variance_inv\n",
    "        variance = 1. / variance_inv\n",
    "        # Step 5. Determine the new value, Sigma', ot the sigma. This\n",
    "        #         computation requires iteration.\n",
    "        sigma = self.determine_sigma(rating, difference, variance)\n",
    "        # Step 6. Update the rating deviation to the new pre-rating period\n",
    "        #         value, Phi*.\n",
    "        phi_star = math.sqrt(rating.phi ** 2 + sigma ** 2)\n",
    "        # Step 7. Update the rating and RD to the new values, Mu' and Phi'.\n",
    "        phi = 1. / math.sqrt(1 / phi_star ** 2 + 1 / variance)\n",
    "        mu = rating.mu + phi ** 2 * (difference / variance)\n",
    "        # Step 8. Convert ratings and RD's back to original scale.\n",
    "        return self.scale_up(self.create_rating(mu, phi, sigma))\n",
    "\n",
    "    def rate_1vs1(self, rating1, rating2, drawn=False):\n",
    "        return (self.rate(rating1, [(DRAW if drawn else WIN, rating2)]),\n",
    "                self.rate(rating2, [(DRAW if drawn else LOSS, rating1)]))\n",
    "\n",
    "    def quality_1vs1(self, rating1, rating2):\n",
    "        expected_score1 = self.expect_score(rating1, rating2, self.reduce_impact(rating1))\n",
    "        expected_score2 = self.expect_score(rating2, rating1, self.reduce_impact(rating2))\n",
    "        expected_score = (expected_score1 + expected_score2) / 2\n",
    "        return 2 * (0.5 - abs(0.5 - expected_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUuVngWiaMN8"
   },
   "outputs": [],
   "source": [
    "# Initialize Glicko\n",
    "glicko2 = Glicko2()\n",
    "\n",
    "# Initialize player ratings\n",
    "ratings = {}\n",
    "initial_rating = Rating(mu=MU, phi=PHI, sigma=SIGMA)\n",
    "\n",
    "# Iterate through matches and update ratings\n",
    "for index, row in atp_matches_before_df.iterrows():\n",
    "    winner = row['winner_id']\n",
    "    loser = row['loser_id']\n",
    "\n",
    "    if winner not in ratings:\n",
    "        ratings[winner] = initial_rating\n",
    "    if loser not in ratings:\n",
    "        ratings[loser] = initial_rating\n",
    "\n",
    "    winner_rating = ratings[winner]\n",
    "    loser_rating = ratings[loser]\n",
    "\n",
    "    new_winner_rating, new_loser_rating = glicko2.rate_1vs1(winner_rating, loser_rating)\n",
    "\n",
    "    ratings[winner] = new_winner_rating\n",
    "    ratings[loser] = new_loser_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rzm5kXshh6_y"
   },
   "outputs": [],
   "source": [
    "# make the index player_id\n",
    "atp_player_features.set_index('player_id', inplace=True)\n",
    "\n",
    "# set the ratings\n",
    "for player_id in atp_player_features.index:\n",
    "    if player_id in ratings:\n",
    "        atp_player_features.loc[player_id, 'rating'] = ratings[player_id].mu\n",
    "        atp_player_features.loc[player_id, 'RD'] = ratings[player_id].phi\n",
    "        atp_player_features.loc[player_id, 'volatility'] = ratings[player_id].sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gy_4zLXlkh0B",
    "outputId": "827a521e-8c47-46d7-824c-a697a293a292"
   },
   "outputs": [],
   "source": [
    "atp_player_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qD4dmIhsyKPk"
   },
   "outputs": [],
   "source": [
    "# update the last match to before, then make function for updating in future\n",
    "last_match_dates = {}\n",
    "\n",
    "for player_id in pd.concat([atp_matches_before_df['winner_id'], atp_matches_before_df['loser_id']]).unique():\n",
    "  winner_matches = atp_matches_before_df[atp_matches_before_df['winner_id'] == player_id]\n",
    "  loser_matches = atp_matches_before_df[atp_matches_before_df['loser_id'] == player_id]\n",
    "\n",
    "  all_matches = pd.concat([winner_matches, loser_matches])\n",
    "\n",
    "  last_match_date = all_matches['tourney_date'].max()\n",
    "  last_match_dates[player_id] = last_match_date\n",
    "\n",
    "def calculate_days_since_last_match(row, player_id):\n",
    "    match_date = row['tourney_date']\n",
    "\n",
    "    if player_id in last_match_dates:\n",
    "        last_date = last_match_dates[player_id]\n",
    "        days_since_last_match = (match_date - last_date).days\n",
    "    else:\n",
    "        days_since_last_match = 365  # No previous matches found\n",
    "\n",
    "    # Update the last match date for the player\n",
    "    last_match_dates[player_id] = match_date\n",
    "\n",
    "    return days_since_last_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emfmtaO9bMSG",
    "outputId": "dec12bc8-40bf-4bbd-9b6c-73f9e51a7f35"
   },
   "outputs": [],
   "source": [
    "# make the matches DataFrame while updating the atp_features DataFrame\n",
    "count = 0\n",
    "new_rows = []\n",
    "previous_year = 2005\n",
    "print(atp_matches_after_df.shape)\n",
    "for index, row in atp_matches_after_df.iterrows():\n",
    "  count += 1\n",
    "  if count % 1000 == 0:\n",
    "    print(count)\n",
    "  if row['tourney_date'].year != previous_year:\n",
    "    previous_year = row['tourney_date'].year\n",
    "    print(previous_year, \" at count = \", count)\n",
    "  rand_num = np.random.rand()\n",
    "  if rand_num > 0.5:\n",
    "    player_1 = row['winner_id']\n",
    "    player_2 = row['loser_id']\n",
    "    result = 1\n",
    "    player_1_height = row['winner_ht']\n",
    "    player_1_hand = 1 if row['winner_hand'] == 'R' else 0\n",
    "    player_2_height = row['loser_ht']\n",
    "    player_2_hand = 1 if row['loser_hand'] == 'R' else 0\n",
    "    player_1_age= row['winner_age']\n",
    "    player_2_age = row['loser_age']\n",
    "  else:\n",
    "    player_1 = row['loser_id']\n",
    "    player_2 = row['winner_id']\n",
    "    player_1_height = row['loser_ht']\n",
    "    player_1_hand = 1 if row['loser_hand'] == 'R' else 0\n",
    "    player_2_height = row['winner_ht']\n",
    "    player_2_hand = 1 if row['winner_hand'] == 'R' else 0\n",
    "    player_1_age= row['loser_age']\n",
    "    player_2_age = row['winner_age']\n",
    "    result = 0\n",
    "\n",
    "  # Deal with player not in ratings yet\n",
    "  if player_1 not in ratings:\n",
    "    ratings[player_1] = initial_rating\n",
    "    atp_player_features.loc[player_1, 'rating'] = new_winner_rating.mu\n",
    "    atp_player_features.loc[player_1, 'RD'] = new_winner_rating.phi\n",
    "    atp_player_features.loc[player_1, 'volatility'] = new_winner_rating.sigma\n",
    "\n",
    "  if player_2 not in ratings:\n",
    "    ratings[player_2] = initial_rating\n",
    "    atp_player_features.loc[player_2, 'rating'] = new_winner_rating.mu\n",
    "    atp_player_features.loc[player_2, 'RD'] = new_winner_rating.phi\n",
    "    atp_player_features.loc[player_2, 'volatility'] = new_winner_rating.sigma\n",
    "\n",
    "  previous_matches = atp_matches_all[atp_matches_all['tourney_date'] < row['tourney_date']]\n",
    "  head_to_head_w_1 = previous_matches[(previous_matches['winner_id'] == player_1) & (previous_matches['loser_id'] == player_2)].shape[0]\n",
    "  head_to_head_w_2 = previous_matches[(previous_matches['winner_id'] == player_2) & (previous_matches['loser_id'] == player_1)].shape[0]\n",
    "  days_since_match_1 = calculate_days_since_last_match(row, player_1)\n",
    "  days_since_match_2 = calculate_days_since_last_match(row, player_2)\n",
    "\n",
    "  # create new row\n",
    "  new_row = {\n",
    "    'date' : row['tourney_date'], # going to drop these features before training\n",
    "    'tournament' : row['tourney_name'],\n",
    "    'winner_name' : row['winner_name'],\n",
    "    'loser_name' : row['loser_name'], # just need them for combining with betting data\n",
    "\n",
    "    'total_wins_1' : atp_player_features.loc[player_1]['total_wins'],\n",
    "    'total_losses_1' : atp_player_features.loc[player_1]['total_losses'],\n",
    "    'total_wins_Hard_1' : atp_player_features.loc[player_1]['total_wins_on_Hard'],\n",
    "    'total_wins_Carpet_1' : atp_player_features.loc[player_1]['total_wins_on_Carpet'],\n",
    "    'total_wins_Clay_1' : atp_player_features.loc[player_1]['total_wins_on_Clay'],\n",
    "    'total_wins_Grass_1' : atp_player_features.loc[player_1]['total_wins_on_Grass'],\n",
    "    'total_losses_Hard_1' : atp_player_features.loc[player_1]['total_losses_on_Hard'],\n",
    "    'total_losses_Carpet_1' : atp_player_features.loc[player_1]['total_losses_on_Carpet'],\n",
    "    'total_losses_Clay_1' : atp_player_features.loc[player_1]['total_losses_on_Clay'],\n",
    "    'total_losses_Grass_1' : atp_player_features.loc[player_1]['total_losses_on_Grass'],\n",
    "    'total_wins_bo3_1' : atp_player_features.loc[player_1]['total_wins_best_of_3'],\n",
    "    'total_wins_bo5_1' : atp_player_features.loc[player_1]['total_wins_best_of_5'],\n",
    "    'total_losses_bo3_1' : atp_player_features.loc[player_1]['total_losses_best_of_3'],\n",
    "    'total_losses_bo5_1' : atp_player_features.loc[player_1]['total_losses_best_of_5'],\n",
    "    'total_wins_against_L_1' : atp_player_features.loc[player_1]['total_wins_vs_L'],\n",
    "    'total_losses_against_L_1' : atp_player_features.loc[player_1]['total_losses_vs_L'],\n",
    "    'total_wins_against_R_1' : atp_player_features.loc[player_1]['total_wins_vs_R'],\n",
    "    'total_losses_against_R_1' : atp_player_features.loc[player_1]['total_losses_vs_R'],\n",
    "    'rating_1' : atp_player_features.loc[player_1]['rating'],\n",
    "    'RD_1' : atp_player_features.loc[player_1]['RD'],\n",
    "    'volatility_1' : atp_player_features.loc[player_1]['volatility'],\n",
    "    'first_serve_win_perc_1': (atp_player_features.loc[player_1]['first_serves_wins'] / atp_player_features.loc[player_1]['total_first_serves']\n",
    "                               if atp_player_features.loc[player_1]['total_first_serves'] != 0 else 0),\n",
    "    'second_serve_win_perc_1': (atp_player_features.loc[player_1]['second_serves_wins'] / atp_player_features.loc[player_1]['total_second_serves']\n",
    "                                if atp_player_features.loc[player_1]['total_second_serves'] != 0 else 0),\n",
    "    'first_return_win_perc_1': (atp_player_features.loc[player_1]['first_return_wins'] / atp_player_features.loc[player_1]['total_first_returns']\n",
    "                                if atp_player_features.loc[player_1]['total_first_returns'] != 0 else 0),\n",
    "    'second_return_win_perc_1': (atp_player_features.loc[player_1]['second_return_wins'] / atp_player_features.loc[player_1]['total_second_returns']\n",
    "                                 if atp_player_features.loc[player_1]['total_second_returns'] != 0 else 0),\n",
    "    'break_point_break_perc_1': (atp_player_features.loc[player_1]['break_points_for_won'] / atp_player_features.loc[player_1]['break_points_for']\n",
    "                                 if atp_player_features.loc[player_1]['break_points_for'] != 0 else 0),\n",
    "    'break_point_save_perc_1': (atp_player_features.loc[player_1]['break_points_against_won'] / atp_player_features.loc[player_1]['break_points_against']\n",
    "                                if atp_player_features.loc[player_1]['break_points_against'] != 0 else 0),\n",
    "    'head_to_head_wins_1' : head_to_head_w_1,\n",
    "    'height_1' : player_1_height,\n",
    "    'age_1' : player_1_age,\n",
    "    'player_1_hand' : player_1_hand,\n",
    "    'days_since_1' : days_since_match_1,\n",
    "\n",
    "    'total_wins_2' : atp_player_features.loc[player_2]['total_wins'],\n",
    "    'total_losses_2' : atp_player_features.loc[player_2]['total_losses'],\n",
    "    'total_wins_Hard_2' : atp_player_features.loc[player_2]['total_wins_on_Hard'],\n",
    "    'total_wins_Carpet_2' : atp_player_features.loc[player_2]['total_wins_on_Carpet'],\n",
    "    'total_wins_Clay_2' : atp_player_features.loc[player_2]['total_wins_on_Clay'],\n",
    "    'total_wins_Grass_2' : atp_player_features.loc[player_2]['total_wins_on_Grass'],\n",
    "    'total_losses_Hard_2' : atp_player_features.loc[player_2]['total_losses_on_Hard'],\n",
    "    'total_losses_Carpet_2' : atp_player_features.loc[player_2]['total_losses_on_Carpet'],\n",
    "    'total_losses_Clay_2' : atp_player_features.loc[player_2]['total_losses_on_Clay'],\n",
    "    'total_losses_Grass_2' : atp_player_features.loc[player_2]['total_losses_on_Grass'],\n",
    "    'total_wins_bo3_2' : atp_player_features.loc[player_2]['total_wins_best_of_3'],\n",
    "    'total_wins_bo5_2' : atp_player_features.loc[player_2]['total_wins_best_of_5'],\n",
    "    'total_losses_bo3_2' : atp_player_features.loc[player_2]['total_losses_best_of_3'],\n",
    "    'total_losses_bo5_2' : atp_player_features.loc[player_2]['total_losses_best_of_5'],\n",
    "    'total_wins_against_L_2' : atp_player_features.loc[player_2]['total_wins_vs_L'],\n",
    "    'total_losses_against_L_2' : atp_player_features.loc[player_2]['total_losses_vs_L'],\n",
    "    'total_wins_against_R_2' : atp_player_features.loc[player_2]['total_wins_vs_R'],\n",
    "    'total_losses_against_R_2' : atp_player_features.loc[player_2]['total_losses_vs_R'],\n",
    "    'rating_2' : atp_player_features.loc[player_2]['rating'],\n",
    "    'RD_2' : atp_player_features.loc[player_2]['RD'],\n",
    "    'volatility_2' : atp_player_features.loc[player_2]['volatility'],\n",
    "    'first_serve_win_perc_2': (atp_player_features.loc[player_2]['first_serves_wins'] / atp_player_features.loc[player_2]['total_first_serves']\n",
    "                               if atp_player_features.loc[player_2]['total_first_serves'] != 0 else 0),\n",
    "    'second_serve_win_perc_2': (atp_player_features.loc[player_2]['second_serves_wins'] / atp_player_features.loc[player_2]['total_second_serves']\n",
    "                                if atp_player_features.loc[player_2]['total_second_serves'] != 0 else 0),\n",
    "    'first_return_win_perc_2': (atp_player_features.loc[player_2]['first_return_wins'] / atp_player_features.loc[player_2]['total_first_returns']\n",
    "                                if atp_player_features.loc[player_2]['total_first_returns'] != 0 else 0),\n",
    "    'second_return_win_perc_2': (atp_player_features.loc[player_2]['second_return_wins'] / atp_player_features.loc[player_2]['total_second_returns']\n",
    "                                 if atp_player_features.loc[player_2]['total_second_returns'] != 0 else 0),\n",
    "    'break_point_break_perc_2': (atp_player_features.loc[player_2]['break_points_for_won'] / atp_player_features.loc[player_2]['break_points_for']\n",
    "                                 if atp_player_features.loc[player_2]['break_points_for'] != 0 else 0),\n",
    "    'break_point_save_perc_2': (atp_player_features.loc[player_2]['break_points_against_won'] / atp_player_features.loc[player_2]['break_points_against']\n",
    "                                if atp_player_features.loc[player_2]['break_points_against'] != 0 else 0),\n",
    "    'head_to_head_wins_2' : head_to_head_w_2,\n",
    "    'height_2' : player_2_height,\n",
    "    'age_2' : player_2_age,\n",
    "    'player_2_hand' : player_2_hand,\n",
    "    'days_since_2' : days_since_match_2,\n",
    "\n",
    "    'Hard' : 1 if row['surface'] == 'Hard' else 0, # surface features\n",
    "    'Carpet' : 1 if row['surface'] == 'Carpet' else 0,\n",
    "    'Clay' : 1 if row['surface'] == 'Clay' else 0,\n",
    "    'Grass' : 1 if row['surface'] == 'Grass' else 0,\n",
    "    'bo3' : 1 if row['best_of'] == 3 else 0, # best of 3 = 1\n",
    "\n",
    "    'result' : result # = 1 if player_1 wins\n",
    "  }\n",
    "\n",
    "  if rand_num > 0.5:\n",
    "    atp_player_features.loc[player_1, 'total_wins'] += 1\n",
    "    atp_player_features.loc[player_2, 'total_losses'] += 1\n",
    "    atp_player_features.loc[player_1, f'total_wins_on_{row[\"surface\"]}'] += 1\n",
    "    atp_player_features.loc[player_2, f'total_losses_on_{row[\"surface\"]}'] += 1\n",
    "    atp_player_features.loc[player_1, f'total_wins_best_of_{row[\"best_of\"]}'] += 1\n",
    "    atp_player_features.loc[player_2, f'total_losses_best_of_{row[\"best_of\"]}'] += 1\n",
    "    atp_player_features.loc[player_1, f'total_wins_vs_{row[\"loser_hand\"]}'] += 1\n",
    "    atp_player_features.loc[player_2, f'total_losses_vs_{row[\"winner_hand\"]}'] += 1\n",
    "\n",
    "    winner_rating = ratings[player_1]\n",
    "    loser_rating = ratings[player_2]\n",
    "\n",
    "    new_winner_rating, new_loser_rating = glicko2.rate_1vs1(winner_rating, loser_rating)\n",
    "\n",
    "    ratings[player_1] = new_winner_rating\n",
    "    ratings[player_2] = new_loser_rating\n",
    "\n",
    "    atp_player_features.loc[player_1, 'rating'] = new_winner_rating.mu\n",
    "    atp_player_features.loc[player_1, 'RD'] = new_winner_rating.phi\n",
    "    atp_player_features.loc[player_1, 'volatility'] = new_winner_rating.sigma\n",
    "\n",
    "    atp_player_features.loc[player_2, 'rating'] = new_loser_rating.mu\n",
    "    atp_player_features.loc[player_2, 'RD'] = new_loser_rating.phi\n",
    "    atp_player_features.loc[player_2, 'volatility'] = new_loser_rating.sigma\n",
    "\n",
    "    atp_player_features.loc[player_1, 'first_serves_wins'] += row['w_1stWon']\n",
    "    atp_player_features.loc[player_1, 'total_first_serves'] += row['w_1stIn']\n",
    "    atp_player_features.loc[player_1, 'second_serves_wins'] += row['w_2ndWon']\n",
    "    atp_player_features.loc[player_1, 'total_second_serves'] += (row['w_svpt'] - row['w_1stIn'])\n",
    "    atp_player_features.loc[player_1, 'first_return_wins'] += (row['l_1stIn'] - row['l_1stWon'])\n",
    "    atp_player_features.loc[player_1, 'total_first_returns'] += row['l_1stIn']\n",
    "    atp_player_features.loc[player_1, 'second_return_wins'] += (row['l_svpt'] - row['l_1stIn'] - row['l_2ndWon'])\n",
    "    atp_player_features.loc[player_1, 'total_second_returns'] += (row['l_svpt'] - row['l_1stIn'])\n",
    "    atp_player_features.loc[player_1, 'break_points_for_won'] += (row['l_bpFaced'] - row['l_bpSaved'])\n",
    "    atp_player_features.loc[player_1, 'break_points_for'] += row['l_bpFaced']\n",
    "    atp_player_features.loc[player_1, 'break_points_against_won'] += row['w_bpSaved']\n",
    "    atp_player_features.loc[player_1, 'break_points_against'] += row['w_bpFaced']\n",
    "\n",
    "    atp_player_features.loc[player_2, 'first_serves_wins'] += row['l_1stWon']\n",
    "    atp_player_features.loc[player_2, 'total_first_serves'] += row['l_1stIn']\n",
    "    atp_player_features.loc[player_2, 'second_serves_wins'] += row['l_2ndWon']\n",
    "    atp_player_features.loc[player_2, 'total_second_serves'] += (row['l_svpt'] - row['l_1stIn'])\n",
    "    atp_player_features.loc[player_2, 'first_return_wins'] += (row['w_1stIn'] - row['w_1stWon'])\n",
    "    atp_player_features.loc[player_2, 'total_first_returns'] += row['w_1stIn']\n",
    "    atp_player_features.loc[player_2, 'second_return_wins'] += (row['w_svpt'] - row['w_1stIn'] - row['w_2ndWon'])\n",
    "    atp_player_features.loc[player_2, 'total_second_returns'] += (row['w_svpt'] - row['w_1stIn'])\n",
    "    atp_player_features.loc[player_2, 'break_points_for_won'] += (row['w_bpFaced'] - row['w_bpSaved'])\n",
    "    atp_player_features.loc[player_2, 'break_points_for'] += row['w_bpFaced']\n",
    "    atp_player_features.loc[player_2, 'break_points_against_won'] += row['l_bpSaved']\n",
    "    atp_player_features.loc[player_2, 'break_points_against'] += row['l_bpFaced']\n",
    "\n",
    "  else:\n",
    "    atp_player_features.loc[player_2, 'total_wins'] += 1\n",
    "    atp_player_features.loc[player_1, 'total_losses'] += 1\n",
    "    atp_player_features.loc[player_2, f'total_wins_on_{row[\"surface\"]}'] += 1\n",
    "    atp_player_features.loc[player_1, f'total_losses_on_{row[\"surface\"]}'] += 1\n",
    "    atp_player_features.loc[player_2, f'total_wins_best_of_{row[\"best_of\"]}'] += 1\n",
    "    atp_player_features.loc[player_1, f'total_losses_best_of_{row[\"best_of\"]}'] += 1\n",
    "    atp_player_features.loc[player_2, f'total_wins_vs_{row[\"loser_hand\"]}'] += 1\n",
    "    atp_player_features.loc[player_1, f'total_losses_vs_{row[\"winner_hand\"]}'] += 1\n",
    "\n",
    "    winner_rating = ratings[player_2]\n",
    "    loser_rating = ratings[player_1]\n",
    "\n",
    "    new_winner_rating, new_loser_rating = glicko2.rate_1vs1(winner_rating, loser_rating)\n",
    "\n",
    "    ratings[player_2] = new_winner_rating\n",
    "    ratings[player_1] = new_loser_rating\n",
    "\n",
    "    atp_player_features.loc[player_2, 'rating'] = new_winner_rating.mu\n",
    "    atp_player_features.loc[player_2, 'RD'] = new_winner_rating.phi\n",
    "    atp_player_features.loc[player_2, 'volatility'] = new_winner_rating.sigma\n",
    "\n",
    "    atp_player_features.loc[player_1, 'rating'] = new_loser_rating.mu\n",
    "    atp_player_features.loc[player_1, 'RD'] = new_loser_rating.phi\n",
    "    atp_player_features.loc[player_1, 'volatility'] = new_loser_rating.sigma\n",
    "\n",
    "    atp_player_features.loc[player_2, 'first_serves_wins'] += row['w_1stWon']\n",
    "    atp_player_features.loc[player_2, 'total_first_serves'] += row['w_1stIn']\n",
    "    atp_player_features.loc[player_2, 'second_serves_wins'] += row['w_2ndWon']\n",
    "    atp_player_features.loc[player_2, 'total_second_serves'] += (row['w_svpt'] - row['w_1stIn'])\n",
    "    atp_player_features.loc[player_2, 'first_return_wins'] += (row['l_1stIn'] - row['l_1stWon'])\n",
    "    atp_player_features.loc[player_2, 'total_first_returns'] += row['l_1stIn']\n",
    "    atp_player_features.loc[player_2, 'second_return_wins'] += (row['l_svpt'] - row['l_1stIn'] - row['l_2ndWon'])\n",
    "    atp_player_features.loc[player_2, 'total_second_returns'] += (row['l_svpt'] - row['l_1stIn'])\n",
    "    atp_player_features.loc[player_2, 'break_points_for_won'] += (row['l_bpFaced'] - row['l_bpSaved'])\n",
    "    atp_player_features.loc[player_2, 'break_points_for'] += row['l_bpFaced']\n",
    "    atp_player_features.loc[player_2, 'break_points_against_won'] += row['w_bpSaved']\n",
    "    atp_player_features.loc[player_2, 'break_points_against'] += row['w_bpFaced']\n",
    "\n",
    "    atp_player_features.loc[player_1, 'first_serves_wins'] += row['l_1stWon']\n",
    "    atp_player_features.loc[player_1, 'total_first_serves'] += row['l_1stIn']\n",
    "    atp_player_features.loc[player_1, 'second_serves_wins'] += row['l_2ndWon']\n",
    "    atp_player_features.loc[player_1, 'total_second_serves'] += (row['l_svpt'] - row['l_1stIn'])\n",
    "    atp_player_features.loc[player_1, 'first_return_wins'] += (row['w_1stIn'] - row['w_1stWon'])\n",
    "    atp_player_features.loc[player_1, 'total_first_returns'] += row['w_1stIn']\n",
    "    atp_player_features.loc[player_1, 'second_return_wins'] += (row['w_svpt'] - row['w_1stIn'] - row['w_2ndWon'])\n",
    "    atp_player_features.loc[player_1, 'total_second_returns'] += (row['w_svpt'] - row['w_1stIn'])\n",
    "    atp_player_features.loc[player_1, 'break_points_for_won'] += (row['w_bpFaced'] - row['w_bpSaved'])\n",
    "    atp_player_features.loc[player_1, 'break_points_for'] += row['w_bpFaced']\n",
    "    atp_player_features.loc[player_1, 'break_points_against_won'] += row['l_bpSaved']\n",
    "    atp_player_features.loc[player_1, 'break_points_against'] += row['l_bpFaced']\n",
    "\n",
    "  new_rows.append(new_row)\n",
    "\n",
    "test_matches_df = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqUgRAWh8PQp",
    "outputId": "64e24a0f-350a-47ac-f54b-47304227807b"
   },
   "outputs": [],
   "source": [
    "# get rid of a few rows that have NaN for whatever reason\n",
    "print(test_matches_df.shape)\n",
    "\n",
    "test_matches_clean = test_matches_df.dropna(axis=0)\n",
    "test_matches_clean.drop(columns = ['winner_name', 'loser_name', 'tournament', 'date'], inplace=True)\n",
    "\n",
    "print(test_matches_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wlnZqWIss0W"
   },
   "outputs": [],
   "source": [
    "X = test_matches_clean.drop(columns=['result'])  # Drop the target column\n",
    "y = test_matches_clean['result']  # Target variable\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hnBNDQM0Ge_B",
    "outputId": "c7e3c12f-e047-482a-d357-77dc754e7897"
   },
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3KQREWvbDgF",
    "outputId": "4890b623-1dee-4c50-d258-a66c424680d9"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',  # Use 'categorical_crossentropy' for multi-class classification\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-T5H2AzbRhM",
    "outputId": "9329a708-1994-447c-f00b-0c7d61a7db13"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=25, batch_size=128, verbose = 2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drfaXH2e-N5A",
    "outputId": "236e0fb9-3bb6-49ff-dab3-967c91bebda6"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKgtO5BADFx3"
   },
   "outputs": [],
   "source": [
    "# def create_model(learning_rate=0.01, dropout_rate=0.0, units=64):\n",
    "#     model = Sequential([\n",
    "#         Dense(units=units, activation='relu', input_shape=(67,)),\n",
    "#         Dropout(dropout_rate),\n",
    "#         Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "#     optimizer = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "#     def __init__(self, learning_rate=0.01, dropout_rate=0.0, units=64, epochs=10, batch_size=32):\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.dropout_rate = dropout_rate\n",
    "#         self.units = units\n",
    "#         self.epochs = epochs\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         self.model = create_model(\n",
    "#             learning_rate=self.learning_rate,\n",
    "#             dropout_rate=self.dropout_rate,\n",
    "#             units=self.units\n",
    "#         )\n",
    "\n",
    "#         self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "#         return self\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         loss, accuracy = self.model.evaluate(X, y, verbose=0)\n",
    "#         return accuracy\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.00001, 0.0001, 0.001],\n",
    "#     'dropout_rate': [0.2, 0.5],\n",
    "#     'units': [75, 100, 125, 150],\n",
    "#     'batch_size': [64, 128, 196],\n",
    "#     'epochs': [20, 30, 40]\n",
    "# }\n",
    "\n",
    "# # Create the model wrapper\n",
    "# model_wrapper = KerasClassifierWrapper()\n",
    "\n",
    "# # Setup the GridSearchCV\n",
    "# grid = GridSearchCV(estimator=model_wrapper, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "\n",
    "# # Perform the grid search\n",
    "# grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Print best parameters and score\n",
    "# print(\"Best parameters:\", grid_result.best_params_)\n",
    "# print(\"Best score:\", grid_result.best_score_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
